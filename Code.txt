#Libraries used

library(dplyr)
library(funModeling)
library(GA)
library(readr)
library(caret)
library(nsga3)
library(tidyverse)

#Importation of dataset
churn <- read_csv("churn4.csv")
churn <- churn[2:21]
churn$Churn <- as.factor(churn$Churn)

#Importation of Dummyvars dataset
dumchurn <- read_csv("churn7.csv")
dumchurn <- dumchurn[2:45]

#  Machine Learning Models
 
 intrain <- createDataPartition(churn$Churn, p=0.7, list=FALSE)
 set.seed(1234)
 training <- churn[intrain,]
 testing <- churn[-intrain,]
 control <- trainControl(method="cv", number=2)
 metric <- "Accuracy"
 fit.gbm <- train(Churn~., data=training, method="gbm", metric=metric, trControl=control, verbose=FALSE)
 fit.rf <- train(Churn~., data=training, method="rf", metric=metric, trControl=control, verbose=FALSE)
 results <- resamples(list(rf=fit.rf, gbm=fit.gbm))
 summary(results)

#Confusion Matrix to test performance 

confusionMatrix(predict(fit.gbm, testing), testing$Churn, positive = 'Yes')
confusionMatrix(predict(fit.rf, testing), testing$Churn, positive = 'Yes')


# Genetic Algorithm 

https://github.com/pablo14/genetic-algorithm-feature-selection



#Fitness function for Genetic Algorithm, this function will measure the model against accuracy
custom_fitness <- function(vars, data_x, data_y, p_sampling)
{
  # speeding up things with sampling
  ix=get_sample(data_x, percentage_tr_rows = p_sampling)
  data_2=data_x[ix,]
  data_y_smp=data_y[ix]
  
  # keep only vars from current solution
  names=colnames(data_2)
  names_2=names[vars==1]
  # get the columns of the current solution
  data_sol=data_2[, names_2]
  
  # get the roc value from the created model
  accuracy_value=get_accuracy_metric(data_sol, data_y_smp, names_2)
  
  # get the total number of vars for the current selection
  q_vars=sum(vars)
  
  # time for your magic
  fitness_value=accuracy_value/q_vars
  
  return(fitness_value)
}


#Accuracy Metric
get_accuracy_metric <- function(data_tr_sample, target, best_vars) 
{
  data_model=select(data_tr_sample, one_of(best_vars))
  
  fitControl <- trainControl(method = "cv", 
                             number = 3, 
                             summaryFunction = twoClassSummary)
  
  data_model=select(data_tr_sample, one_of(best_vars))
  
  mtry = sqrt(ncol(data_model))
 
  
  fit_model_1 = train(x=data_model, 
                      y= target, 
                      method = "gbm")
 
  
 
  metric=fit_model_1$results["Accuracy"][1,1]
  return(metric)
} 


#Parameters set for the GA function
main <- select(dumchurn, -Churn)
targ <- as.factor(dumchurn$Churn)
col_names <- colnames(main)
param_nBits <- ncol(main)

#GA function
GA_1 <- ga(fitness = function(vars) custom_fitness(vars = vars, data_x = main, data_y = targ, p_sampling = 0.7), type = "binary", # optimization data type
            crossover=gabin_uCrossover,  # cross-over method
            elitism = 2, # number of best ind. to pass to next iteration
            pmutation = 0.04, # mutation rate prob
            popSize = 100, # the number of indivduals/solutions
            nBits = param_nBits, # total number of variables
            names=col_names, # variable name
            run=5, # max iter without improvement (stopping criteria)
            maxiter = 100, # total runs or generations
            monitor=plot, # plot the result at each iteration
            keepBest = TRUE, # keep the best solution at the end
            parallel = T, # allow parallel procesing
            seed=84211 # for reproducibility purposes
 )
 

#Summarising performance
summary(GA_1)
 

#Extracting best features
best_vars_ga=col_names[GA_1@solution[1,]==1]
 

#ML model to test performance of the best features

featurechurn <- dumchurn[best_vars_ga]
featurechurn$Churn <- dumchurn$Churn
featurechurn$Churn <- as.factor(featurechurn$Churn)


 intrain1 <- createDataPartition(featurechurn$Churn, p=0.7, list=FALSE)
 set.seed(1234)
 training1 <- featurechurn[intrain1,]
 testing1 <- featurechurn[-intrain1,]
 fit.gbm1 <- train(Churn~., data=training1, method="gbm", metric=metric, trControl=control, verbose=FALSE)
 fit.rf1 <- train(Churn~., data=training1, method="rf", metric=metric, trControl=control, verbose=FALSE)
 results <- resamples(list(rf=fit.rf, gbm=fit.gbm))
 summary(results)

confusionMatrix(predict(fit.gbm1, testing1), testing1$Churn, positive = 'Yes')
confusionMatrix(predict(fit.rf1, testing1), testing1$Churn, positive = 'Yes')
 


# NSGA-II Feature Selection


churn <- read_csv("churn4.csv")
churn <- churn[2:21]

library(mlr)

churn1 <- churn %>% mutate(Churn = factor(ifelse(Churn == "Yes", "1", "2")))
dmy <- dummyVars(" ~ .", data = churn1)
churn3 <- data.frame(predict(dmy, newdata = churn1))
churn3 <- cbind(churn3, churn1$Churn)
churn3$Churn.1 <- NULL
churn3$Churn.2 <- NULL
colnames(churn3)[44] <- "Churn"


mrf <- mlr::makeLearner("classif.randomForest", predict.type = "prob")

gbm_learner <- mlr::makeLearner("classif.gbm", predict.type = "prob")


rsmp <- mlr::makeResampleDesc("CV", iters = 2)
measures <- list(mlr::mmce)

f_auc <- function(pred){auc <- mlr::performance(pred, auc)
return(as.numeric(auc))}
objective <- c(f_auc)
o_names <- c("AUC", "nf")
par <- rPref::high(AUC)*rPref::low(nf)

xgboostnsga3 <- nsga3fs(df = churn3, target = "Churn", obj_list = objective,
obj_names = o_names, pareto = par, pop_size = 100, max_gen = 100,
model = gbm_learner, resampling = rsmp,
num_features = TRUE, r_measures = measures, cpus = 2)

nsga4fsplot <- nsga3fs(df = churn3, target = "Churn", obj_list = objective,
obj_names = o_names, pareto = par, pop_size = 50, max_gen = 100,
model = mrf, resampling = rsmp,
num_features = TRUE, r_measures = measures, cpus = 2)

plot(xgboostnsga3$pf_raw$objective_values)
plot(nsga4fsplot$pf_raw$objective_values)
 


 
 
 